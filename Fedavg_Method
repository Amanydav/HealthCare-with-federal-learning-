import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
)

# ------------------------- CONFIG -------------------------
dataset_path = r"/content/drive/MyDrive/diabetes.csv"
target_col = "Outcome"

num_clients = 3
rounds = 30
local_epochs = 5
local_lr = 0.001
random_state = 42

# ------------------------- Model -------------------------
def create_model(input_dim):
    model = tf.kerasSequential = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(input_dim,)),
        tf.keras.layers.Dense(128, activation="relu"),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(64, activation="relu"),
        tf.keras.layers.Dense(1, activation="sigmoid")
    ])
    return model

# ------------------------- Weight Utilities -------------------------
def get_weights_vector(weights):
    return np.concatenate([w.flatten() for w in weights])

def set_weights_from_vector(model, vec, template_weights):
    new_weights, idx = [], 0
    for w in template_weights:
        size = np.prod(w.shape)
        new_weights.append(vec[idx:idx + size].reshape(w.shape))
        idx += size
    model.set_weights(new_weights)

# ------------------------- Dataset -------------------------
def load_data(csv_path, target_col):
    df = pd.read_csv(csv_path)

    X = df.drop(columns=[target_col]).values
    y = df[target_col].values.astype(np.int32)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=random_state
    )

    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train).astype(np.float32)
    X_test = scaler.transform(X_test).astype(np.float32)

    return X_train, X_test, y_train, y_test

# ------------------------- IID Client Split -------------------------
def split_data_iid(X, y, num_clients):
    idxs = np.random.permutation(len(X))
    X, y = X[idxs], y[idxs]
    splits = np.array_split(np.arange(len(X)), num_clients)
    return [(X[s], y[s]) for s in splits]

# ------------------------- Local Training -------------------------
def local_train(model, X, y):
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=local_lr),
        loss="binary_crossentropy"
    )

    model.fit(
        X, y,
        epochs=local_epochs,
        batch_size=32,
        class_weight={0: 1.0, 1: 2.0},
        verbose=0
    )
    return model.get_weights()

# ------------------------- FedAvg -------------------------
def aggregate_fedavg(weight_vectors, sizes):
    total = sum(sizes)
    agg = np.zeros_like(weight_vectors[0])
    for w, s in zip(weight_vectors, sizes):
        agg += (s / total) * w
    return agg

# ------------------------- Evaluation -------------------------
def evaluate(model, global_vec, template_weights, X_test, y_test):
    set_weights_from_vector(model, global_vec, template_weights)

    y_pred = (model.predict(X_test, verbose=0) >= 0.5).astype(int).reshape(-1)

    return (
        accuracy_score(y_test, y_pred),
        precision_score(y_test, y_pred, zero_division=0),
        recall_score(y_test, y_pred, zero_division=0),
        f1_score(y_test, y_pred, zero_division=0),
        confusion_matrix(y_test, y_pred)
    )

# ------------------------- Simulation -------------------------
def simulate_fedavg():
    X_train, X_test, y_train, y_test = load_data(dataset_path, target_col)
    clients = split_data_iid(X_train, y_train, num_clients)

    input_dim = X_train.shape[1]
    template_weights = create_model(input_dim).get_weights()
    global_vec = get_weights_vector(template_weights)

    acc_hist = []
    final_metrics = None

    for _ in range(rounds):
        client_vecs, client_sizes = [], []

        for Xc, yc in clients:
            local_model = create_model(input_dim)
            set_weights_from_vector(local_model, global_vec, template_weights)

            new_weights = local_train(local_model, Xc, yc)
            client_vecs.append(get_weights_vector(new_weights))
            client_sizes.append(len(Xc))

        global_vec = aggregate_fedavg(client_vecs, client_sizes)

        final_metrics = evaluate(
            create_model(input_dim),
            global_vec,
            template_weights,
            X_test,
            y_test
        )
        acc_hist.append(final_metrics[0])

    acc, prec, rec, f1, cm = final_metrics

    print("\n==========  FEDAVG (BEST DECENTRALIZED RESULTS) ==========")
    print(f"Accuracy  : {acc:.4f}")
    print(f"Precision : {prec:.4f}")
    print(f"Recall    : {rec:.4f}")
    print(f"F1 Score  : {f1:.4f}")
    print("Confusion Matrix:")
    print(cm)

    plt.plot(range(1, rounds + 1), acc_hist)
    plt.xlabel("Communication Rounds")
    plt.ylabel("Accuracy")
    plt.title("IID FedAvg Accuracy (Upper Bound)")
    plt.grid(True)
    plt.show()

# ------------------------- Run -------------------------
if __name__ == "__main__":
    simulate_fedavg()
